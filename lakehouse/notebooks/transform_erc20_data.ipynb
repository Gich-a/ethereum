{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48474f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lakehouse/notebooks/transform_erc20_data.ipynb\n",
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # ERC20 Transfer Data Transformation\n",
    "# MAGIC \n",
    "# MAGIC This notebook processes raw ERC20 transfer data and creates enriched datasets\n",
    "# MAGIC for analytics and real-time dashboards.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "from delta.tables import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ERC20Transformation\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc8a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Token Configuration and Metadata\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Define token metadata\n",
    "token_metadata = {\n",
    "    \"0xdAC17F958D2ee523a2206206994597C13D831ec7\": {\"symbol\": \"USDT\", \"name\": \"Tether USD\", \"decimals\": 6},\n",
    "    \"0xA0b86a33E6441986C3a3E95c9B95f5d9ed87D8b\": {\"symbol\": \"USDC\", \"name\": \"USD Coin\", \"decimals\": 6},\n",
    "    \"0x6B175474E89094C44Da98b954EedeAC495271d0F\": {\"symbol\": \"DAI\", \"name\": \"Dai Stablecoin\", \"decimals\": 18},\n",
    "    \"0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2\": {\"symbol\": \"WETH\", \"name\": \"Wrapped Ether\", \"decimals\": 18}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0c8a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create broadcast variable for efficient joins\n",
    "token_metadata_broadcast = spark.sparkContext.broadcast(token_metadata)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Read Raw ERC20 Transfer Data\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Read raw ERC20 transfer data\n",
    "raw_transfers_df = spark.read \\\n",
    "    .format(\"delta\") \\\n",
    "    .load(\"Tables/raw/erc20_transfers_raw\")\n",
    "\n",
    "print(\"Raw ERC20 transfers schema:\")\n",
    "raw_transfers_df.printSchema()\n",
    "print(f\"\\nTotal raw transfers: {raw_transfers_df.count()}\")\n",
    "\n",
    "# Show sample data\n",
    "raw_transfers_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7882c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Data Quality and Validation\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Data quality checks\n",
    "print(\"=== DATA QUALITY CHECKS ===\")\n",
    "print(f\"Total records: {raw_transfers_df.count()}\")\n",
    "print(f\"Records with null transaction_hash: {raw_transfers_df.filter(col('transaction_hash').isNull()).count()}\")\n",
    "print(f\"Records with null contract_address: {raw_transfers_df.filter(col('contract_address').isNull()).count()}\")\n",
    "print(f\"Records with zero value: {raw_transfers_df.filter(col('value') == 0).count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e339c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check address formats\n",
    "invalid_addresses = raw_transfers_df.filter(\n",
    "    ~col(\"from_address\").rlike(\"^0x[0-9a-fA-F]{40}$\") |\n",
    "    ~col(\"to_address\").rlike(\"^0x[0-9a-fA-F]{40}$\")\n",
    ").count()\n",
    "print(f\"Records with invalid address format: {invalid_addresses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55582f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = raw_transfers_df.groupBy(\"transaction_hash\", \"from_address\", \"to_address\", \"value\") \\\n",
    "    .count().filter(col(\"count\") > 1).count()\n",
    "print(f\"Duplicate transfers: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99992fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Transform Raw Data to Curated Format\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# UDF to get token metadata\n",
    "def get_token_info(contract_address):\n",
    "    metadata = token_metadata_broadcast.value.get(contract_address.lower())\n",
    "    if metadata:\n",
    "        return metadata[\"symbol\"], metadata[\"name\"], metadata[\"decimals\"]\n",
    "    return \"UNKNOWN\", \"Unknown Token\", 18\n",
    "\n",
    "get_token_info_udf = udf(get_token_info, StructType([\n",
    "    StructField(\"symbol\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"decimals\", IntegerType(), True)\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffcdae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform raw transfers to curated format\n",
    "curated_transfers_df = raw_transfers_df \\\n",
    "    .withColumn(\"timestamp_dt\", to_timestamp(col(\"timestamp\"))) \\\n",
    "    .withColumn(\"date\", date_format(col(\"timestamp_dt\"), \"yyyy-MM-dd\")) \\\n",
    "    .withColumn(\"hour\", hour(col(\"timestamp_dt\"))) \\\n",
    "    .withColumn(\"contract_address_lower\", lower(col(\"contract_address\"))) \\\n",
    "    .withColumn(\"token_info\", get_token_info_udf(col(\"contract_address_lower\"))) \\\n",
    "    .withColumn(\"token_symbol\", col(\"token_info.symbol\")) \\\n",
    "    .withColumn(\"token_name\", col(\"token_info.name\")) \\\n",
    "    .withColumn(\"token_decimals\", col(\"token_info.decimals\")) \\\n",
    "    .withColumn(\"value_normalized\", col(\"value\") / pow(10, col(\"token_decimals\"))) \\\n",
    "    .withColumn(\"transfer_type\", \n",
    "               when(col(\"from_address\") == \"0x0000000000000000000000000000000000000000\", \"mint\")\n",
    "               .when(col(\"to_address\") == \"0x0000000000000000000000000000000000000000\", \"burn\")\n",
    "               .otherwise(\"transfer\")) \\\n",
    "    .withColumn(\"gas_cost_eth\", when(col(\"gas_price\").isNotNull() & col(\"gas_used\").isNotNull(),\n",
    "                                   col(\"gas_price\") * col(\"gas_used\") / pow(10, 18))) \\\n",
    "    .drop(\"token_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out unknown tokens and invalid transfers\n",
    "curated_transfers_df = curated_transfers_df.filter(\n",
    "    (col(\"token_symbol\") != \"UNKNOWN\") & \n",
    "    (col(\"value_normalized\") > 0)\n",
    ")\n",
    "\n",
    "print(\"Curated transfers schema:\")\n",
    "curated_transfers_df.printSchema()\n",
    "print(f\"Curated transfers count: {curated_transfers_df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a95825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Add Transfer Analytics\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Add transfer size categories\n",
    "curated_transfers_df = curated_transfers_df \\\n",
    "    .withColumn(\"transfer_size_category\",\n",
    "               when(col(\"value_normalized\") < 100, \"Small\")\n",
    "               .when(col(\"value_normalized\") < 10000, \"Medium\")\n",
    "               .when(col(\"value_normalized\") < 100000, \"Large\")\n",
    "               .otherwise(\"Whale\")) \\\n",
    "    .withColumn(\"is_large_transfer\", col(\"value_normalized\") >= 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time-based features\n",
    "curated_transfers_df = curated_transfers_df \\\n",
    "    .withColumn(\"day_of_week\", dayofweek(col(\"timestamp_dt\"))) \\\n",
    "    .withColumn(\"is_weekend\", when(col(\"day_of_week\").isin([1, 7]), True).otherwise(False)) \\\n",
    "    .withColumn(\"time_period\",\n",
    "               when(col(\"hour\").between(0, 5), \"Night\")\n",
    "               .when(col(\"hour\").between(6, 11), \"Morning\")\n",
    "               .when(col(\"hour\").between(12, 17), \"Afternoon\")\n",
    "               .otherwise(\"Evening\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562a1ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Write Curated Data\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Write curated transfers to delta table\n",
    "curated_transfers_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"date\", \"token_symbol\") \\\n",
    "    .save(\"Tables/curated/erc20_transfers_curated\")\n",
    "\n",
    "print(\"Curated ERC20 transfer data written successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51818ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Create Aggregated Views\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Token daily aggregations\n",
    "daily_token_agg = curated_transfers_df \\\n",
    "    .groupBy(\"date\", \"token_symbol\", \"token_name\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"transfer_count\"),\n",
    "        countDistinct(\"from_address\").alias(\"unique_senders\"),\n",
    "        countDistinct(\"to_address\").alias(\"unique_receivers\"),\n",
    "        countDistinct(\"transaction_hash\").alias(\"unique_transactions\"),\n",
    "        sum(\"value_normalized\").alias(\"total_volume\"),\n",
    "        avg(\"value_normalized\").alias(\"avg_transfer_size\"),\n",
    "        min(\"value_normalized\").alias(\"min_transfer\"),\n",
    "        max(\"value_normalized\").alias(\"max_transfer\"),\n",
    "        stddev(\"value_normalized\").alias(\"transfer_size_stddev\"),\n",
    "        sum(when(col(\"transfer_size_category\") == \"Whale\", 1).otherwise(0)).alias(\"whale_transfers\"),\n",
    "        sum(when(col(\"transfer_type\") == \"mint\", col(\"value_normalized\")).otherwise(0)).alias(\"minted_amount\"),\n",
    "        sum(when(col(\"transfer_type\") == \"burn\", col(\"value_normalized\")).otherwise(0)).alias(\"burned_amount\"),\n",
    "        avg(\"gas_cost_eth\").alias(\"avg_gas_cost_eth\")\n",
    "    ) \\\n",
    "    .withColumn(\"volume_category\",\n",
    "               when(col(\"total_volume\") < 1000000, \"Low\")\n",
    "               .when(col(\"total_volume\") < 10000000, \"Medium\")\n",
    "               .when(col(\"total_volume\") < 100000000, \"High\")\n",
    "               .otherwise(\"Very High\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4256d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly aggregations for real-time dashboard\n",
    "hourly_token_agg = curated_transfers_df \\\n",
    "    .groupBy(\"date\", \"hour\", \"token_symbol\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"transfer_count\"),\n",
    "        sum(\"value_normalized\").alias(\"total_volume\"),\n",
    "        avg(\"value_normalized\").alias(\"avg_transfer_size\"),\n",
    "        countDistinct(\"from_address\").alias(\"unique_senders\"),\n",
    "        countDistinct(\"to_address\").alias(\"unique_receivers\"),\n",
    "        sum(when(col(\"is_large_transfer\"), 1).otherwise(0)).alias(\"large_transfers\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Address activity aggregations\n",
    "daily_address_agg = curated_transfers_df \\\n",
    "    .withColumn(\"address\", col(\"from_address\")) \\\n",
    "    .withColumn(\"flow_type\", lit(\"outbound\")) \\\n",
    "    .select(\"date\", \"address\", \"token_symbol\", \"value_normalized\", \"flow_type\") \\\n",
    "    .union(\n",
    "        curated_transfers_df \\\n",
    "        .withColumn(\"address\", col(\"to_address\")) \\\n",
    "        .withColumn(\"flow_type\", lit(\"inbound\")) \\\n",
    "        .select(\"date\", \"address\", \"token_symbol\", \"value_normalized\", \"flow_type\")\n",
    "    ) \\\n",
    "    .groupBy(\"date\", \"address\", \"token_symbol\") \\\n",
    "    .agg(\n",
    "        sum(when(col(\"flow_type\") == \"inbound\", col(\"value_normalized\")).otherwise(0)).alias(\"inbound_volume\"),\n",
    "        sum(when(col(\"flow_type\") == \"outbound\", col(\"value_normalized\")).otherwise(0)).alias(\"outbound_volume\"),\n",
    "        count(when(col(\"flow_type\") == \"inbound\", 1)).alias(\"inbound_count\"),\n",
    "        count(when(col(\"flow_type\") == \"outbound\", 1)).alias(\"outbound_count\")\n",
    "    ) \\\n",
    "    .withColumn(\"net_volume\", col(\"inbound_volume\") - col(\"outbound_volume\")) \\\n",
    "    .withColumn(\"total_activity\", col(\"inbound_volume\") + col(\"outbound_volume\")) \\\n",
    "    .filter(col(\"total_activity\") > 1000)  # Filter for significant activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cba4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Write Aggregated Data\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Write daily token aggregations\n",
    "daily_token_agg.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"Tables/aggregated/erc20_daily_tokens\")\n",
    "\n",
    "# Write hourly token aggregations\n",
    "hourly_token_agg.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"date\") \\\n",
    "    .save(\"Tables/aggregated/erc20_hourly_tokens\")\n",
    "\n",
    "# Write address activity aggregations\n",
    "daily_address_agg.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"date\") \\\n",
    "    .save(\"Tables/aggregated/erc20_address_activity\")\n",
    "\n",
    "print(\"All aggregated ERC20 data written successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4ed512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Cross-Token Analysis\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Token correlation analysis\n",
    "token_correlation = daily_token_agg \\\n",
    "    .select(\"date\", \"token_symbol\", \"total_volume\") \\\n",
    "    .groupBy(\"date\") \\\n",
    "    .pivot(\"token_symbol\") \\\n",
    "    .agg(first(\"total_volume\"))\n",
    "\n",
    "# Market dominance analysis\n",
    "market_share = daily_token_agg \\\n",
    "    .withColumn(\"date_volume\", sum(\"total_volume\").over(Window.partitionBy(\"date\"))) \\\n",
    "    .withColumn(\"market_share\", col(\"total_volume\") / col(\"date_volume\") * 100) \\\n",
    "    .select(\"date\", \"token_symbol\", \"total_volume\", \"market_share\", \"transfer_count\")\n",
    "\n",
    "market_share.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"Tables/aggregated/erc20_market_share\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Summary and Validation\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"=== TRANSFORMATION SUMMARY ===\")\n",
    "print(f\"Raw transfers processed: {raw_transfers_df.count()}\")\n",
    "print(f\"Curated transfers created: {curated_transfers_df.count()}\")\n",
    "print(f\"Daily token aggregations: {daily_token_agg.count()}\")\n",
    "print(f\"Hourly token aggregations: {hourly_token_agg.count()}\")\n",
    "print(f\"Address activity records: {daily_address_agg.count()}\")\n",
    "\n",
    "print(\"\\n=== TOKEN SUMMARY (Last 7 Days) ===\")\n",
    "recent_summary = daily_token_agg \\\n",
    "    .filter(col(\"date\") >= date_sub(current_date(), 7)) \\\n",
    "    .groupBy(\"token_symbol\") \\\n",
    "    .agg(\n",
    "        sum(\"total_volume\").alias(\"weekly_volume\"),\n",
    "        sum(\"transfer_count\").alias(\"weekly_transfers\"),\n",
    "        avg(\"avg_transfer_size\").alias(\"avg_transfer_size\")\n",
    "    ) \\\n",
    "    .orderBy(desc(\"weekly_volume\"))\n",
    "\n",
    "recent_summary.show()\n",
    "\n",
    "print(\"\\n=== TOP ADDRESSES BY ACTIVITY ===\")\n",
    "top_addresses = daily_address_agg \\\n",
    "    .filter(col(\"date\") == date_sub(current_date(), 1)) \\\n",
    "    .orderBy(desc(\"total_activity\")) \\\n",
    "    .limit(10)\n",
    "\n",
    "top_addresses.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad4db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Create Views for Dashboard\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Create temporary views for dashboard queries\n",
    "curated_transfers_df.createOrReplaceTempView(\"erc20_transfers_realtime\")\n",
    "daily_token_agg.createOrReplaceTempView(\"erc20_daily_summary\")\n",
    "hourly_token_agg.createOrReplaceTempView(\"erc20_hourly_summary\")\n",
    "market_share.createOrReplaceTempView(\"erc20_market_share\")\n",
    "\n",
    "print(\"Views created successfully for dashboard queries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a06f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %sql\n",
    "# MAGIC -- Optimize delta tables for better query performance\n",
    "# MAGIC OPTIMIZE delta.`Tables/curated/erc20_transfers_curated` ZORDER BY (timestamp_dt, token_symbol);\n",
    "# MAGIC OPTIMIZE delta.`Tables/aggregated/erc20_daily_tokens` ZORDER BY (date, token_symbol);\n",
    "# MAGIC OPTIMIZE delta.`Tables/aggregated/erc20_hourly_tokens` ZORDER BY (date, hour, token_symbol);\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Data Quality Metrics Export\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Create data quality metrics for monitoring\n",
    "data_quality_metrics = spark.createDataFrame([\n",
    "    (\"erc20_transfers\", \"record_count\", float(curated_transfers_df.count())),\n",
    "    (\"erc20_transfers\", \"unique_tokens\", float(curated_transfers_df.select(\"token_symbol\").distinct().count())),\n",
    "    (\"erc20_transfers\", \"avg_daily_volume\", float(daily_token_agg.agg(avg(\"total_volume\")).collect()[0][0] or 0)),\n",
    "    (\"erc20_transfers\", \"data_freshness_hours\", float(24))  # Placeholder - would calculate actual freshness\n",
    "], [\"table_name\", \"metric_name\", \"metric_value\"])\n",
    "\n",
    "data_quality_metrics.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(\"Tables/monitoring/data_quality_metrics\")\n",
    "\n",
    "print(\"Data quality metrics exported for monitoring\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
